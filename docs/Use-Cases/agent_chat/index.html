<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v0.0.0-4193">
<link rel="alternate" type="application/rss+xml" href="/autogen/blog/rss.xml" title="AutoGen RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/autogen/blog/atom.xml" title="AutoGen Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous"><title data-react-helmet="true">Multi-agent Conversation Framework | AutoGen</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Multi-agent Conversation Framework | AutoGen"><meta data-react-helmet="true" name="description" content="AutoGen offers a unified multi-agent conversation framework as a high-level abstraction of using foundation models. It features capable, customizable and conversable agents which integrate LLM, tool and human via automated agent chat."><meta data-react-helmet="true" property="og:description" content="AutoGen offers a unified multi-agent conversation framework as a high-level abstraction of using foundation models. It features capable, customizable and conversable agents which integrate LLM, tool and human via automated agent chat."><link data-react-helmet="true" rel="shortcut icon" href="/autogen/img/ag.ico"><link data-react-helmet="true" rel="canonical" href="https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat"><link data-react-helmet="true" rel="alternate" href="https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat" hreflang="x-default"><link rel="stylesheet" href="/autogen/assets/css/styles.a35b243d.css">
<link rel="preload" href="/autogen/assets/js/runtime~main.2fc86b75.js" as="script">
<link rel="preload" href="/autogen/assets/js/main.ea1eb4c2.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/autogen/"><div class="navbar__logo"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">AutoGen</b></a><a class="navbar__item navbar__link navbar__link--active" href="/autogen/docs/Getting-Started">Docs</a><a class="navbar__item navbar__link" href="/autogen/docs/reference/agentchat/conversable_agent">SDK</a><a class="navbar__item navbar__link" href="/autogen/blog">Blog</a><a class="navbar__item navbar__link" href="/autogen/docs/FAQ">FAQ</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/microsoft/autogen" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">ðŸŒœ</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">ðŸŒž</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div><div class="navbar__search searchBarContainer_I7kZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_Zg7X searchBarLoadingRing_J5Ez"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_CDc6"><kbd class="searchHint_2RRg">ctrl</kbd><kbd class="searchHint_2RRg">K</kbd></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_lDyR"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_i9tI" type="button"></button><aside class="docSidebarContainer_0YBq"><div class="sidebar_a3j0"><nav class="menu thin-scrollbar menu_cyFh"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/autogen/docs/Getting-Started">Getting Started</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/autogen/docs/Installation">Installation</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#">Use Cases</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/autogen/docs/Use-Cases/agent_chat">Multi-agent Conversation Framework</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/Use-Cases/enhanced_inference">Enhanced Inference</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Examples</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/autogen/docs/Contribute">Contributing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/autogen/docs/Research">Research</a></li></ul></nav></div></aside><main class="docMainContainer_r8cw"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_zHA2"><div class="docItemContainer_oiyr"><article><div class="tocCollapsible_aw-L theme-doc-toc-mobile tocMobile_Tx6Y"><button type="button" class="clean-btn tocCollapsibleButton_zr6a">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Multi-agent Conversation Framework</h1></header><p>AutoGen offers a unified multi-agent conversation framework as a high-level abstraction of using foundation models. It features capable, customizable and conversable agents which integrate LLM, tool and human via automated agent chat.
By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code.</p><p>This framework simplifies the orchestration, automation and optimization of a complex LLM workflow. It maximizes the performance of LLM models and overcome their weaknesses. It enables building next-gen LLM applications based on multi-agent conversations with minimal effort.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="agents">Agents<a aria-hidden="true" class="hash-link" href="#agents" title="Direct link to heading">â€‹</a></h3><p>AutoGen abstracts and implements conversable agents
designed to solve tasks through inter-agent conversations. Specifically, the agents in AutoGen have the following notable features:</p><ul><li><p>Conversable: Agents in AutoGen are conversable, which means that any agent can send
and receive messages from other agents to initiate or continue a conversation</p></li><li><p>Customizable: Agents in AutoGen can be customized to integrate LLMs, humans, tools, or a combination of them.</p></li></ul><p>The figure below shows the built-in agents in AutoGen.
<img alt="Agent Chat Example" src="/autogen/assets/images/autogen_agents-b80434bcb15d46da0c6cbeed28115f38.png"></p><p>We have designed a generic <code>ConversableAgent</code> class for Agents that are capable of conversing with each other through the exchange of messages to jointly finish a task. An agent can communicate with other agents and perform actions. Different agents can differ in what actions they perform after receiving messages. Two representative subclasses are <code>AssistantAgent</code> and <code>UserProxyAgent</code>.</p><ul><li><p>The <code>AssistantAgent</code> is designed to act as an AI assistant, using LLMs by default but not requiring human input or code execution. It could write Python code (in a Python coding block) for a user to execute when a message (typically a description of a task that needs to be solved) is received. Under the hood, the Python code is written by LLM (e.g., GPT-4). It can also receive the execution results and suggest corrections or bug fixes. Its behavior can be altered by passing a new system message. The LLM <a href="#enhanced-inference">inference</a> configuration can be configured via <code>llm_config</code>.</p></li><li><p>The <code>UserProxyAgent</code> is conceptually a proxy agent for humans, soliciting human input as the agent&#x27;s reply at each interaction turn by default and also having the capability to execute code and call functions. The <code>UserProxyAgent</code> triggers code execution automatically when it detects an executable code block in the received message and no human user input is provided. Code execution can be disabled by setting the <code>code_execution_config</code> parameter to False. LLM-based response is disabled by default. It can be enabled by setting <code>llm_config</code> to a dict corresponding to the <a href="/autogen/docs/Use-Cases/enhanced_inference">inference</a> configuration. When <code>llm_config</code> is set as a dictionary, <code>UserProxyAgent</code> can generate replies using an LLM when code execution is not performed.</p></li></ul><p>The auto-reply capability of <code>ConversableAgent</code> allows for more autonomous multi-agent communication while retaining the possibility of human intervention.
One can also easily extend it by registering reply functions with the <code>register_reply()</code> method.</p><p>In the following code, we create an <code>AssistantAgent</code> named &quot;assistant&quot; to serve as the assistant and a <code>UserProxyAgent</code> named &quot;user_proxy&quot; to serve as a proxy for the human user. We will later employ these two agents to solve a task.</p><div class="codeBlockContainer_J+bg language-python"><div class="codeBlockContent_csEI python"><pre tabindex="0" class="prism-code language-python codeBlock_rtdJ thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> autogen </span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> AssistantAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> UserProxyAgent</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># create an AssistantAgent instance named &quot;assistant&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">assistant </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> AssistantAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;assistant&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># create a UserProxyAgent instance named &quot;user_proxy&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">user_proxy </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> UserProxyAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;user_proxy&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_y2LR" id="multi-agent-conversations">Multi-agent Conversations<a aria-hidden="true" class="hash-link" href="#multi-agent-conversations" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_y2LR" id="a-basic-two-agent-conversation-example">A Basic Two-Agent Conversation Example<a aria-hidden="true" class="hash-link" href="#a-basic-two-agent-conversation-example" title="Direct link to heading">â€‹</a></h3><p>Once the participating agents are constructed properly, one can start a multi-agent conversation session by an initialization step as shown in the following code:</p><div class="codeBlockContainer_J+bg language-python"><div class="codeBlockContent_csEI python"><pre tabindex="0" class="prism-code language-python codeBlock_rtdJ thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#bfc7d5"><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># the assistant receives a message from the user, which contains the task description</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">user_proxy</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">initiate_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    assistant</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token triple-quoted-string string" style="color:rgb(195, 232, 141)">&quot;&quot;&quot;What date is today? Which big tech stock has the largest year-to-date gain this year? How much is the gain?&quot;&quot;&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div><p>After the initialization step, the conversation could proceed automatically. Find a visual illustration of how the user_proxy and assistant collaboratively solve the above task autonmously below:
<img alt="Agent Chat Example" src="/autogen/assets/images/agent_example-a965f253ce7d8e1548ff819e19edc5e4.png"></p><ol><li>The assistant receives a message from the user_proxy, which contains the task description.</li><li>The assistant then tries to write Python code to solve the task and sends the response to the user_proxy.</li><li>Once the user_proxy receives a response from the assistant, it tries to reply by either soliciting human input or preparing an automatically generated reply. If no human input is provided, the user_proxy executes the code and uses the result as the auto-reply.</li><li>The assistant then generates a further response for the user_proxy. The user_proxy can then decide whether to terminate the conversation. If not, steps 3 and 4 are repeated.</li></ol><h3 class="anchor anchorWithStickyNavbar_y2LR" id="supporting-diverse-conversation-patterns">Supporting Diverse Conversation Patterns<a aria-hidden="true" class="hash-link" href="#supporting-diverse-conversation-patterns" title="Direct link to heading">â€‹</a></h3><h4 class="anchor anchorWithStickyNavbar_y2LR" id="conversations-with-different-levels-of-autonomy-and-human-involvement-patterns">Conversations with different levels of autonomy, and human-involvement patterns<a aria-hidden="true" class="hash-link" href="#conversations-with-different-levels-of-autonomy-and-human-involvement-patterns" title="Direct link to heading">â€‹</a></h4><p>On the one hand, one can achieve fully autonomous conversations after an initialization step. On the other hand, AutoGen can be used to implement human-in-the-loop problem-solving by configuring human involvement levels and patterns (e.g., setting the <code>human_input_mode</code> to <code>ALWAYS</code>), as human involvement is expected and/or desired in many applications.</p><h4 class="anchor anchorWithStickyNavbar_y2LR" id="static-and-dynamic-conversations">Static and dynamic conversations<a aria-hidden="true" class="hash-link" href="#static-and-dynamic-conversations" title="Direct link to heading">â€‹</a></h4><p>By adopting the conversation-driven control with both programming language and natural language, AutoGen inherently allows dynamic conversation. Dynamic conversation allows the agent topology to change depending on the actual flow of conversation under different input problem instances, while the flow of a static conversation always follows a pre-defined topology. The dynamic conversation pattern is useful in complex applications where the patterns of interaction cannot be predetermined in advance. AutoGen provides two general approaches to achieving dynamic conversation:</p><ul><li><p>Registered auto-reply. With the pluggable auto-reply function, one can choose to invoke conversations with other agents depending on the content of the current message and context. A working system demonstrating this type of dynamic conversation can be found in this code example, demonstrating a <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb" target="_blank" rel="noopener noreferrer">dynamic group chat</a>. In the system, we register an auto-reply function in the group chat manager, which lets LLM decide who the next speaker will be in a group chat setting.</p></li><li><p>LLM-based function call. In this approach, LLM decides whether or not to call a particular function depending on the conversation status in each inference call.
By messaging additional agents in the called functions, the LLM can drive dynamic multi-agent conversation. A working system showcasing this type of dynamic conversation can be found in the <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb" target="_blank" rel="noopener noreferrer">multi-user math problem solving scenario</a>, where a student assistant would automatically resort to an expert using function calls.</p></li></ul><h3 class="anchor anchorWithStickyNavbar_y2LR" id="diverse-applications-implemented-with-autogen">Diverse Applications Implemented with AutoGen<a aria-hidden="true" class="hash-link" href="#diverse-applications-implemented-with-autogen" title="Direct link to heading">â€‹</a></h3><p>The figure below shows six examples of applications built using AutoGen.
<img alt="Applications" src="/autogen/assets/images/app-b0acafd5e331fa9471ab6d0e7010a83d.png"></p><ol><li><p><strong>Code Generation, Execution, and Debugging</strong></p><ul><li>Automated Task Solving with Code Generation, Execution &amp; Debugging - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_auto_feedback_from_code_execution.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Auto Code Generation, Execution, Debugging and Human Feedback - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_human_feedback.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Automated Code Generation and Question Answering with Retrieval Augmented Agents - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_RetrieveChat.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li></ul></li><li><p><strong>Multi-Agent Collaboration (&gt;3 Agents)</strong></p><ul><li>Automated Task Solving with GPT-4 + Multiple Human Users - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Automated Task Solving by Group Chat (with 3 group member agents and 1 manager agent) - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Automated Data Visualization by Group Chat (with 3 group member agents and 1 manager agent) - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_vis.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Automated Complex Task Solving by Group Chat (with 6 group member agents and 1 manager agent) - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Automated Task Solving with Coding &amp; Planning Agents - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_planning.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Automated Task Solving with agents divided into 2 groups - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_hierarchy_flow_using_select_speaker.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li></ul></li><li><p><strong>Applications</strong></p><ul><li>Automated Chess Game Playing &amp; Chitchatting by GPT-4 Agents - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_chess.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Automated Continual Learning from New Data - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_stream.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li><a href="https://github.com/microsoft/optiguide" target="_blank" rel="noopener noreferrer">OptiGuide</a> - Coding, Tool Using, Safeguarding &amp; Question Anwering for Supply Chain Optimization</li></ul></li><li><p><strong>Tool Use</strong></p><ul><li><strong>Web Search</strong>: Solve Tasks Requiring Web Info - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_web_info.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Use Provided Tools as Functions - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_function_call.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Task Solving with Langchain Provided Tools as Functions - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_langchain.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li><strong>RAG</strong>: Group Chat with Retrieval Augmented Generation (with 5 group member agents and 1 manager agent) - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_RAG.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>In-depth Guide to OpenAI Utility Functions - <a href="https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li></ul></li><li><p><strong>Agent Teaching and Learning</strong></p><ul><li>Teach Agents New Skills &amp; Reuse via Automated Chat - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_teaching.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Teach Agents New Facts, User Preferences and Skills Beyond Coding - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_teachability.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li></ul></li><li><p><strong>Multi-Agent Chat with OpenAI Assistants in the loop</strong></p><ul><li>Hello-World Chat with OpenAi Assistant in AutoGen - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_twoagents_basic.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Chat with OpenAI Assistant using Function Call - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_function_call.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Chat with OpenAI Assistant with Code Interpreter - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_code_interpreter.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>Chat with OpenAI Assistant with Retrieval Augmentation - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_retrieval.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li><li>OpenAI Assistant in a Group Chat - <a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_oai_assistant_groupchat.ipynb" target="_blank" rel="noopener noreferrer">View Notebook</a></li></ul></li></ol><h2 class="anchor anchorWithStickyNavbar_y2LR" id="for-further-reading">For Further Reading<a aria-hidden="true" class="hash-link" href="#for-further-reading" title="Direct link to heading">â€‹</a></h2><p><em>Interested in the research that leads to this package? Please check the following papers.</em></p><ul><li><p><a href="https://arxiv.org/abs/2308.08155" target="_blank" rel="noopener noreferrer">AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework</a>. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang and Chi Wang. ArXiv 2023.</p></li><li><p><a href="https://arxiv.org/abs/2306.01337" target="_blank" rel="noopener noreferrer">An Empirical Study on Challenging Math Problem Solving with GPT-4</a>. Yiran Wu, Feiran Jia, Shaokun Zhang, Hangyu Li, Erkang Zhu, Yue Wang, Yin Tat Lee, Richard Peng, Qingyun Wu, Chi Wang. ArXiv preprint arXiv:2306.01337 (2023).</p></li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/microsoft/autogen/edit/main/website/docs/Use-Cases/agent_chat.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_mS5F" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_mt2f"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/autogen/docs/Installation"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« <!-- -->Installation</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/autogen/docs/Use-Cases/enhanced_inference"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Enhanced Inference<!-- --> Â»</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_vrFS thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#agents" class="table-of-contents__link toc-highlight">Agents</a></li><li><a href="#multi-agent-conversations" class="table-of-contents__link toc-highlight">Multi-agent Conversations</a><ul><li><a href="#a-basic-two-agent-conversation-example" class="table-of-contents__link toc-highlight">A Basic Two-Agent Conversation Example</a></li><li><a href="#supporting-diverse-conversation-patterns" class="table-of-contents__link toc-highlight">Supporting Diverse Conversation Patterns</a></li><li><a href="#diverse-applications-implemented-with-autogen" class="table-of-contents__link toc-highlight">Diverse Applications Implemented with AutoGen</a></li></ul></li><li><a href="#for-further-reading" class="table-of-contents__link toc-highlight">For Further Reading</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://discord.gg/pAbnFJrkgZ" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://twitter.com/pyautogen" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2023 AutoGen Authors.</div></div></div></footer></div>
<script src="/autogen/assets/js/runtime~main.2fc86b75.js"></script>
<script src="/autogen/assets/js/main.ea1eb4c2.js"></script>
</body>
</html>