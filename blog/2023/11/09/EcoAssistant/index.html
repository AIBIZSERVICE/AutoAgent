<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v0.0.0-4193">
<link rel="alternate" type="application/rss+xml" href="/autogen/blog/rss.xml" title="AutoGen RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/autogen/blog/atom.xml" title="AutoGen Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous"><title data-react-helmet="true">EcoAssistant - Using LLM Assistants More Accurately and Affordably | AutoGen</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://microsoft.github.io/autogen/blog/2023/11/09/EcoAssistant"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" property="og:title" content="EcoAssistant - Using LLM Assistants More Accurately and Affordably | AutoGen"><meta data-react-helmet="true" name="description" content="system"><meta data-react-helmet="true" property="og:description" content="system"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2023-11-09T00:00:00.000Z"><meta data-react-helmet="true" property="article:author" content="https://jieyuz2.github.io/"><meta data-react-helmet="true" property="article:tag" content="LLM,RAG,cost-effectiveness"><link data-react-helmet="true" rel="shortcut icon" href="/autogen/img/ag.ico"><link data-react-helmet="true" rel="canonical" href="https://microsoft.github.io/autogen/blog/2023/11/09/EcoAssistant"><link data-react-helmet="true" rel="alternate" href="https://microsoft.github.io/autogen/blog/2023/11/09/EcoAssistant" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://microsoft.github.io/autogen/blog/2023/11/09/EcoAssistant" hreflang="x-default"><link rel="stylesheet" href="/autogen/assets/css/styles.d208c800.css">
<link rel="preload" href="/autogen/assets/js/runtime~main.38db2ed9.js" as="script">
<link rel="preload" href="/autogen/assets/js/main.4723ecaf.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/autogen/"><div class="navbar__logo"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">AutoGen</b></a><a class="navbar__item navbar__link" href="/autogen/docs/Getting-Started">Docs</a><a class="navbar__item navbar__link" href="/autogen/docs/reference/agentchat/conversable_agent">SDK</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/autogen/blog">Blog</a><a class="navbar__item navbar__link" href="/autogen/docs/FAQ">FAQ</a><a class="navbar__item navbar__link" href="/autogen/docs/Examples">Examples</a><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link">Resources</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/autogen/docs/Ecosystem">Ecosystem</a></li><li><a class="dropdown__link" href="/autogen/docs/Gallery">Gallery</a></li></ul></div></div><div class="navbar__items navbar__items--right"><a href="https://github.com/microsoft/autogen" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">ðŸŒœ</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">ðŸŒž</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div><div class="navbar__search searchBarContainer_I7kZ"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_Zg7X searchBarLoadingRing_J5Ez"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_CDc6"><kbd class="searchHint_2RRg">ctrl</kbd><kbd class="searchHint_2RRg">K</kbd></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_q+wC thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_9G5K margin-bottom--md">Recent posts</div><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/12/01/AutoGenAssistant">AutoGen Assistant: Interactively Explore Multi-Agent Workflows</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/11/26/Agent-AutoBuild">Agent AutoBuild - Automatically Building Multi-agent Systems</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/11/20/AgentEval">How to Assess Utility of LLM-powered Applications?</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/11/13/OAI-assistants">AutoGen Meets GPTs</a></li><li class="sidebarItem_cjdF"><a aria-current="page" class="sidebarItemLink_zyXk sidebarItemLinkActive_wcJs" href="/autogen/blog/2023/11/09/EcoAssistant">EcoAssistant - Using LLM Assistants More Accurately and Affordably</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/11/06/LMM-Agent">Multimodal with GPT-4V and LLaVA</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/10/26/TeachableAgent">AutoGen&#x27;s TeachableAgent</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/10/18/RetrieveChat">Retrieval-Augmented Generation (RAG) Applications with AutoGen</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/07/14/Local-LLMs">Use AutoGen for Local LLMs</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/06/28/MathChat">MathChat - An Conversational Framework to Solve Math Problems</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/05/18/GPT-adaptive-humaneval">Achieve More, Pay Less - Use GPT-4 Smartly</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/autogen/blog/2023/04/21/LLM-tuning-math">Does Model and Inference Parameter Matter in LLM Applications? - A Case Study for MATH</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_d4p0" itemprop="headline">EcoAssistant - Using LLM Assistants More Accurately and Affordably</h1><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2023-11-09T00:00:00.000Z" itemprop="datePublished">November 9, 2023</time> Â· <!-- -->5 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://jieyuz2.github.io/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://github.com/jieyuz2.png" alt="Jieyu Zhang"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://jieyuz2.github.io/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Jieyu Zhang</span></a></div><small class="avatar__subtitle" itemprop="description">PhD student at University of Washington</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p><img alt="system" src="/autogen/assets/images/system-1f6d283e77b49cac460bb999adb6bd5d.png"></p><p><strong>TL;DR:</strong></p><ul><li>Introducing the <strong>EcoAssistant</strong>, which is designed to solve user queries more accurately and affordably.</li><li>We show how to let the LLM assistant agent leverage external API to solve user query.</li><li>We show how to reduce the cost of using GPT models via <strong>Assistant Hierachy</strong>.</li><li>We show how to leverage the idea of Retrieval-augmented Generation (RAG) to improve the success rate via <strong>Solution Demonstration</strong>.</li></ul><h2 class="anchor anchorWithStickyNavbar_y2LR" id="ecoassistant">EcoAssistant<a aria-hidden="true" class="hash-link" href="#ecoassistant" title="Direct link to heading">â€‹</a></h2><p>In this blog, we introduce the <strong>EcoAssistant</strong>, a system built upon AutoGen with the goal of solving user queries more accurately and affordably.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="problem-setup">Problem setup<a aria-hidden="true" class="hash-link" href="#problem-setup" title="Direct link to heading">â€‹</a></h3><p>Recently, users have been using conversational LLMs such as ChatGPT for various queries.
Reports indicate that 23% of ChatGPT user queries are for knowledge extraction purposes.
Many of these queries require knowledge that is external to the information stored within any pre-trained large language models (LLMs).
These tasks can only be completed by generating code to fetch necessary information via external APIs that contain the requested information.
In the table below, we show three types of user queries that we aim to address in this work.</p><table><thead><tr><th>Dataset</th><th>API</th><th>Example query</th></tr></thead><tbody><tr><td>Places</td><td><a href="https://developers.google.com/maps/documentation/places/web-service/overview" target="_blank" rel="noopener noreferrer">Google Places</a></td><td>Iâ€™m looking for a 24-hour pharmacy in Montreal, can you find one for me?</td></tr><tr><td>Weather</td><td><a href="https://www.weatherapi.com" target="_blank" rel="noopener noreferrer">Weather API</a></td><td>What is the current cloud coverage in Mumbai, India?</td></tr><tr><td>Stock</td><td><a href="https://www.alphavantage.co/documentation/" target="_blank" rel="noopener noreferrer">Alpha Vantage Stock API</a></td><td>Can you give me the opening price of Microsoft for the month of January 2023?</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_y2LR" id="leveraging-external-apis">Leveraging external APIs<a aria-hidden="true" class="hash-link" href="#leveraging-external-apis" title="Direct link to heading">â€‹</a></h3><p>To address these queries, we first build a <strong>two-agent system</strong> based on AutoGen,
where the first agent is a <strong>LLM assistant agent</strong> (<code>AssistantAgent</code> in AutoGen) that is responsible for proposing and refining the code and
the second agent is a <strong>code executor agent</strong> (<code>UserProxyAgent</code> in AutoGen) that would extract the generated code and execute it, forwarding the output back to the LLM assistant agent.
A visualization of the two-agent system is shown below.</p><p><img alt="chat" src="/autogen/assets/images/chat-a2adea6a92b3cd4059021840c869d7d5.png"></p><p>To instruct the assistant agent to leverage external APIs, we only need to add the API name/key dictionary at the beginning of the initial message.
The template is shown below, where the red part is the information of APIs and black part is user query.</p><p><img alt="template" src="/autogen/assets/images/template-c610ae53eaa7afa3adaf670fa74b5c10.png"></p><p>Importantly, we don&#x27;t want to reveal our real API key to the assistant agent for safety concerns.
Therefore, we use a <strong>fake API key</strong> to replace the real API key in the initial message.
In particular, we generate a random token (e.g., <code>181dbb37</code>) for each API key and replace the real API key with the token in the initial message.
Then, when the code executor execute the code, the fake API key would be automatically replaced by the real API key.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="solution-demonstration">Solution Demonstration<a aria-hidden="true" class="hash-link" href="#solution-demonstration" title="Direct link to heading">â€‹</a></h3><p>In most practical scenarios, queries from users would appear sequentially over time.
Our <strong>EcoAssistant</strong> leverages past success to help the LLM assistants address future queries via <strong>Solution Demonstration</strong>.
Specifically, whenever a query is deemed successfully resolved by user feedback, we capture and store the query and the final generated code snippet.
These query-code pairs are saved in a specialized vector database. When new queries appear, <strong>EcoAssistant</strong> retrieves the most similar query from the database, which is then appended with the associated code to the initial prompt for the new query, serving as a demonstration.
The new template of initial message is shown below, where the blue part corresponds to the solution demonstration.</p><p><img alt="template" src="/autogen/assets/images/template-demo-5a8cae3df56acdcf73188e401ad739f5.png"></p><p>We found that this utilization of past successful query-code pairs improves the query resolution process with fewer iterations and enhances the system&#x27;s performance.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="assistant-hierarchy">Assistant Hierarchy<a aria-hidden="true" class="hash-link" href="#assistant-hierarchy" title="Direct link to heading">â€‹</a></h3><p>LLMs usually have different prices and performance, for example, GPT-3.5-turbo is much cheaper than GPT-4 but also less accurate.
Thus, we propose the <strong>Assistant Hierarchy</strong> to reduce the cost of using LLMs.
The core idea is that we use the cheaper LLMs first and only use the more expensive LLMs when necessary.
By this way, we are able to reduce the reliance on expensive LLMs and thus reduce the cost.
In particular, given multiple LLMs, we initiate one assistant agent for each and start the conversation with the most cost-effective LLM assistant.
If the conversation between the current LLM assistant and the code executor concludes without successfully resolving the query, <strong>EcoAssistant</strong> would then restart the conversation with the next more expensive LLM assistant in the hierarchy.
We found that this strategy significantly reduces costs while still effectively addressing queries.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="a-synergistic-effect">A Synergistic Effect<a aria-hidden="true" class="hash-link" href="#a-synergistic-effect" title="Direct link to heading">â€‹</a></h3><p>We found that the <strong>Assistant Hierarchy</strong> and <strong>Solution Demonstration</strong> of <strong>EcoAssistant</strong> have a synergistic effect.
Because the query-code database is shared by all LLM assistants, even without specialized design,
the solution from more powerful LLM assistant (e.g., GPT-4) could be later retrieved to guide weaker LLM assistant (e.g., GPT-3.5-turbo).
Such a synergistic effect further improves the performance and reduces the cost of <strong>EcoAssistant</strong>.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="experimental-results">Experimental Results<a aria-hidden="true" class="hash-link" href="#experimental-results" title="Direct link to heading">â€‹</a></h3><p>We evaluate <strong>EcoAssistant</strong> on three datasets: Places, Weather, and Stock. When comparing it with a single GPT-4 assistant, we found that <strong>EcoAssistant</strong> achieves a higher success rate with a lower cost as shown in the figure below.
For more details about the experimental results and other experiments, please refer to our <a href="https://arxiv.org/abs/2310.03046" target="_blank" rel="noopener noreferrer">paper</a>.</p><p><img alt="exp" src="/autogen/assets/images/results-4c8cfbb728760a85ce2d549fd7798179.png"></p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="further-reading">Further reading<a aria-hidden="true" class="hash-link" href="#further-reading" title="Direct link to heading">â€‹</a></h2><p>Please refer to our <a href="https://arxiv.org/abs/2310.03046" target="_blank" rel="noopener noreferrer">paper</a> and <a href="https://github.com/JieyuZ2/EcoAssistant" target="_blank" rel="noopener noreferrer">codebase</a> for more details about <strong>EcoAssistant</strong>.</p><p>If you find this blog useful, please consider citing:</p><div class="codeBlockContainer_J+bg language-bibtex"><div class="codeBlockContent_csEI bibtex"><pre tabindex="0" class="prism-code language-bibtex codeBlock_rtdJ thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_1zSZ"><span class="token-line" style="color:#bfc7d5"><span class="token plain">@article{zhang2023ecoassistant,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  title={EcoAssistant: Using LLM Assistant More Affordably and Accurately},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  author={Zhang, Jieyu and Krishna, Ranjay and Awadallah, Ahmed H and Wang, Chi},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  journal={arXiv preprint arXiv:2310.03046},</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  year={2023}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB clean-btn">Copy</button></div></div></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_xD8n"><div class="col"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/autogen/blog/tags/llm">LLM</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/autogen/blog/tags/rag">RAG</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/autogen/blog/tags/cost-effectiveness">cost-effectiveness</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/autogen/blog/2023/11/13/OAI-assistants"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Â« <!-- -->AutoGen Meets GPTs</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/autogen/blog/2023/11/06/LMM-Agent"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Multimodal with GPT-4V and LLaVA<!-- --> Â»</div></a></div></nav></main><div class="col col--2"><div class="tableOfContents_vrFS thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#ecoassistant" class="table-of-contents__link toc-highlight">EcoAssistant</a><ul><li><a href="#problem-setup" class="table-of-contents__link toc-highlight">Problem setup</a></li><li><a href="#leveraging-external-apis" class="table-of-contents__link toc-highlight">Leveraging external APIs</a></li><li><a href="#solution-demonstration" class="table-of-contents__link toc-highlight">Solution Demonstration</a></li><li><a href="#assistant-hierarchy" class="table-of-contents__link toc-highlight">Assistant Hierarchy</a></li><li><a href="#a-synergistic-effect" class="table-of-contents__link toc-highlight">A Synergistic Effect</a></li><li><a href="#experimental-results" class="table-of-contents__link toc-highlight">Experimental Results</a></li></ul></li><li><a href="#further-reading" class="table-of-contents__link toc-highlight">Further reading</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://discord.gg/pAbnFJrkgZ" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://twitter.com/pyautogen" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2023 AutoGen Authors |  <a target="_blank" href="https://privacy.microsoft.com/en-us/privacystatement">Privacy and Cookies</a></div></div></div></footer></div>
<script src="/autogen/assets/js/runtime~main.38db2ed9.js"></script>
<script src="/autogen/assets/js/main.4723ecaf.js"></script>
</body>
</html>